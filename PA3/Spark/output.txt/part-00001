(u'##\xa0Contributing', 1)
(u'## A Note About Hadoop Versions', 1)
(u'Please refer to the build documentation at', 1)
(u'for information on how to get started contributing to the project.', 1)
(u'Spark is built using [Apache Maven](http://maven.apache.org/).', 1)
(u'will run the Pi example locally.', 1)
(u'can be run using:', 1)
(u'Alternatively, if you prefer Python, you can use the Python shell:', 1)
(u'## Interactive Python Shell', 1)
(u'storage systems. Because the protocols have changed in different versions of', 1)
(u'Please see the guidance on how to', 1)
(u'Please refer to the [Configuration Guide](http://spark.apache.org/docs/latest/configuration.html)', 1)
(u'in the online documentation for an overview on how to configure Spark.', 1)
(u'["Building Spark"](http://spark.apache.org/docs/latest/building-spark.html).', 1)
(u'You can build Spark using more than one thread by using the -T option with Maven, see ["Parallel builds in Maven 3"](https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3).', 1)
(u'examples to a cluster. This can be a mesos:// or spark:// URL,', 1)
(u'Many of the example programs print usage help if no params are given.', 1)
(u'guide, on the [project web page](http://spark.apache.org/documentation.html).', 1)
(u'Try the following command, which should return 1000:', 1)
(u'    ./dev/run-tests', 1)
(u'    build/mvn -DskipTests clean package', 1)
(u'Hadoop, you must build Spark against the same version that your cluster runs.', 1)
(u'high-level APIs in Scala, Java, Python, and R, and an optimized engine that', 1)
(u'    scala> sc.parallelize(1 to 1000).count()', 1)
(u'locally with one thread, or "local[N]" to run locally with N threads. You', 1)
(u'[http://spark.apache.org/developer-tools.html](the Useful Developer Tools page).', 1)
(u'For general development tips, including info on developing Spark using an IDE, see ', 1)
(u'(You do not need to do this if you downloaded a pre-built package.)', 1)
(u'You can set the MASTER environment variable when running examples to submit', 1)
(u'This README file only contains basic setup instructions.', 1)
(u'Please review the [Contribution to Spark guide](http://spark.apache.org/contributing.html)', 1)
(u'supports general computation graphs for data analysis. It also supports a', 1)
(u'building for particular Hive and Hive Thriftserver distributions.', 1)
